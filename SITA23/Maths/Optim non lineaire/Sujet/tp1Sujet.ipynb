{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/!\\    Important : à la fin de la séance déposez votre travail sur la page e-campus du cours en un seul fichier nommé  votrenom.ipynb  /!\\\n",
    "              \n",
    "\n",
    "# Algorithmes de gradient (GD) de gradient stochastique (SGD) pour la régression en grande dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce TP, nous allons utiliser  la technique du gradient et gradient stochastique pour résoudre la régression Ridge\n",
    "\n",
    "\\begin{equation}\n",
    "\\min_x f(x):=\\frac{1}{2n}\\|Ax-b\\|^2+\\frac{\\gamma}{2} \\|x\\|^2=\\frac{1}{2n}\\displaystyle\\sum_{i=1}^n(a_i^\\top x -b)^2+\\frac{\\gamma}{2} \\|x\\|^2 \\qquad\\qquad (1_\\gamma)\n",
    "\\end{equation}\n",
    "où $A\\in\\mathbb{R}^{n\\times d}$, $b\\in\\mathbb{R}^n$ et $\\gamma$ est un paramètre de régularisation positif.\n",
    "C'est une régression linéaire avec \"une contrainte\" quadratique sur les coefficients.\n",
    "Ce terme est ajouté pour pallier la présence de colinéarité de certaines variables explicatives (ce qui est probable lorsque il a beaucoup de variables). Il vise aussi à empêcher le modèle de sur-ajuster les données.\n",
    "\n",
    "La solution de ($1_\\gamma$) peut s’exprimer de façon exacte\n",
    "$$x^* = (A^TA+ \\gamma I)^{-1} A^Tb.$$\n",
    "On voit qu’il est possible de choisir un $\\gamma$ pour lequel la matrice $A^TA+\\gamma I$ est inversible. \n",
    "En grande dimension en revanche, l'inversion de cette matrice n'est pas possible et un gradient stochastique est utilisé à la place.\n",
    "\n",
    "On signale que la fonction $f$ est $\\mu$ fortement convexe avec $\\mu=\\lambda_{min}(\\nabla^2 f(x))=\\frac{1}{n}\\lambda_{min}(A^T A)+\\gamma$  et à gradient $L$-Lipschitz avec $L=\\lambda_{max}(\\nabla^2 f(x))=\\frac{1}{n}\\lambda_{max}(A^T A)+\\gamma$.\n",
    "\n",
    "Nous allons procéder en en plusieurs étapes :\n",
    "\n",
    "- Charger les données qui vont nous servir pour tester nos algorithmes. Construire la matrice $A$ et el vecteur $b$ associés. Calculer les valeurs des constantes $\\mu$  et $L$\n",
    "- Implémenter et tester l'algorithme de gradient sur ce jeu de données\n",
    "- Implémenter et tester l'algorithme de gradient stochastique sur ce jeu de données\n",
    "- Observer le rôle du paramètre $\\gamma.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons d'abord charger quelques packages utiles :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "On veut prédire la pression acoustique (sound pressure $SSPL$) générée par une voilure (aile par exemple) à partir de plusieurs entrées mesurées :\n",
    "\n",
    "\n",
    "![airfold.png](airfold.png)\n",
    "\n",
    "1. Frequency, in Hertz ($f$).\n",
    "2. Angle of attack, in degrees ($\\alpha$).\n",
    "3. Chord length, in meters ($c$).\n",
    "4. Free-stream velocity, in meters per second ($u_\\infty$).\n",
    "5. Suction side displacement thickness, in  ($\\delta$).\n",
    "\n",
    "Nous cherchons une relation de la forme \n",
    "$$ SSPL= a_0+a_1 f+ a_2\\alpha + a_3 c+ a_4 u_\\infty + a_5\\delta$$\n",
    "\n",
    "Nous allons d'abord charger les données contenues dans le fichiers airfoil_train.csv et airfoil_test.csv. Les premières serviront à apprendre les coefficients et les secondes pour evaluer l'erreur du modèle sur des nouvelles données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.190304125830146\n",
      "1.0535685918369527e-11\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv(\"airfoil_train.csv\",delimiter=\"\\t\", usecols=[0, 1, 2, 3, 4, 5])\n",
    "\n",
    "b = df['SndPres'].to_numpy()\n",
    "a = df[['Freq', 'Angle', 'ChordL', 'Veloc', 'SucThick']].to_numpy()\n",
    "\n",
    "num_samples =len(b)\n",
    "mean_a= np.mean(a)\n",
    "std_a = np.std(a)\n",
    "a = a - mean_a\n",
    "a = a / std_a\n",
    "A = np.c_[np.ones(num_samples), a]\n",
    "lmax=max(np.linalg.eig(A.T@A)[0])/len(b)\n",
    "lmin=min(np.linalg.eig(A.T@A)[0])/len(b)\n",
    "print(lmax)\n",
    "print(lmin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithme de gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compléter les fonctions python suivantes qui implémentent respectivement la fonction-objectif et son gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_fun(A,b,gamma,x):\n",
    "    ''' x est un np.array'''\n",
    "    #A completer\n",
    "\n",
    "def gd_obj_fun(A,b,gamma,x):\n",
    "    ''' x est un np.array'''\n",
    "    #A completer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compléter l’implémentation de l'algorithme de gradient avec pas constant pour résoudre le problème ($1_\\gamma$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algoGD(A,b,gamma,x0, pas, epsilon, nIterMax):\n",
    "    ''' Algo de GRADIENT pour resoudre le probleme 1_gamma\n",
    "    - x0                  point de depart : np.array : R^n\n",
    "    - pas                 valeur du pas   \n",
    "    - espsilon, nIterMax  pour les criteres d'arrets\n",
    "     Sorties :  \n",
    "    -X =[x0,....xk] :  liste qui contient les iteres xk\n",
    "    -F = [f(x0),....f(xk)] :  liste des valeurs de f au cours des iterations en xk \n",
    "    '''\n",
    "    # A completer\n",
    "    \n",
    "    return X, F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tester cet algorithme sur les données chargées ci-dessus en choisissant $\\gamma=0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma =0.0001\n",
    "x0 = np.zeros(A.shape[1])\n",
    "pas=  0.1\n",
    "epsilon=  0.00001\n",
    "nIterMax= 10000\n",
    "X,F= algoGD(A,b,gamma,x0, pas, epsilon,nIterMax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici peut calculer analytiquement $x^*$. Traçons la courbe $f(x_k)-f(x^*)$ en fonction du nombre d'itérations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_star = np.linalg.solve(A.T@A/A.shape[0]+ gamma*np.eye(A.shape[1]), A.T@b/A.shape[0])\n",
    "best_obj= obj_fun(A,b,gamma,x_star)\n",
    "plt.title('Taux de convergence', fontsize = 20)\n",
    "plt.loglog(F-best_obj,label='GD')\n",
    "plt.xlabel('iteration k'  , fontsize = 20)\n",
    "plt.ylabel(r'$f(x_k) - f(x^*)$', fontsize = 20)\n",
    "plt.legend(fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithme de gradient stochastique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En vous inspirant de ce qui précède implémenter l'algorithme de gradient stochastique (Algorithme 5, page 182 du polycopié). On prendra un pas constant. Faire des tests avec $\\gamma\\in\\{0, 0.0001\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd_obj_fun(A,b,gamma,x):\n",
    "    ''' x est un np.array'''\n",
    "    #A completer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algoSGD(A,b,gamma,x0, pas, nIterMax):\n",
    "    ''' Algo de GRADIENT pour resoudre le probleme 1_gamma\n",
    "    - x0                  point de depart : np.array : R^n\n",
    "    - pas                 valeur du pas   \n",
    "    - nIterMax  pour le critere d'arret\n",
    "     Sorties :  \n",
    "    -X =[x0,....xk] :  liste qui contient les iteres xk\n",
    "    -F = [f(x0),....f(xk)] :  liste des valeurs de f au cours des iterations en xk \n",
    "    -BestF=[] : liste, BestF[i] meilleure valeur trouvee jusqu a l'itération i\n",
    "    '''\n",
    "    # A completer\n",
    "    return X, F, bestF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.0001\n",
    "x0 = np.zeros(A.shape[1])\n",
    "pas= 0.1\n",
    "nIterMax= 10000\n",
    "Xs,Fs, BestFs = algoSGD(A,b,gamma,x0, pas,nIterMax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traçons les courbes de $f(x_k)-f(x^*)$ et de $\\min_{i\\leq k} f(x_i) -f(x^*)$ en fonction du nombre d'itérations $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_star = np.linalg.solve(A.T@A/A.shape[0]+ gamma*np.eye(A.shape[1]), A.T@b/A.shape[0])\n",
    "best_obj= obj_fun(A,b,gamma,x_star)\n",
    "plt.title('Taux de convergence', fontsize = 20)\n",
    "plt.loglog(Fs-best_obj, label='SGD')\n",
    "plt.loglog(BestFs-best_obj, label='BestSGD')\n",
    "plt.xlabel('iteration k'  , fontsize = 20)\n",
    "plt.ylabel(r'$f(x_k) - f(x^*)$', fontsize = 20)\n",
    "plt.legend(fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intérêt de la régularisation\n",
    "On charge maintenant un nouveau jeu de données pour evaluer la qualité du modèle obtenu et observer le rôle du paramètre $\\gamma$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "dft = pd.read_csv(\"airfoil_test.csv\",delimiter=\"\\t\", usecols=[0, 1, 2, 3, 4, 5])\n",
    "\n",
    "bt = dft['SndPres'].to_numpy()\n",
    "at = dft[['Freq', 'Angle', 'ChordL', 'Veloc', 'SucThick']].to_numpy()\n",
    "\n",
    "num_samples_test =len(at)\n",
    "mean_at= np.mean(at)\n",
    "std_at = np.std(at)\n",
    "at = at - mean_at\n",
    "at = at / std_at\n",
    "At = np.c_[np.ones(num_samples_test), at]\n",
    "\n",
    "\n",
    "\n",
    "gamma=0\n",
    "x_star = np.linalg.solve(A.T@A/A.shape[0]+ gamma*np.eye(A.shape[1]), A.T@b/A.shape[0])\n",
    "\n",
    "\n",
    "print(\"Erreur moyenne sur la base d'apprentissage avec gamma ={a:10.4f} est {b:10.2f}\".format(a=gamma, b=np.mean((A@x_star-b)**2))) \n",
    "print(\"Erreur moyenne sur la base de test avec gamma ={a:10.4f} est {b:10.2f}\".format(a=gamma, b=\n",
    "                                                                                      np.mean((At@x_star-bt)**2))) \n",
    "\n",
    "gamma=0.0001\n",
    "x_star = np.linalg.solve(A.T@A/A.shape[0]+ gamma*np.eye(A.shape[1]), A.T@b/A.shape[0])\n",
    "print(\"Erreur moyenne sur la base d'apprentissage avec gamma ={a:10.4f} est {b:10.2f}\".format(a=gamma, b=np.mean((A@x_star-b)**2))) \n",
    "print(\"Erreur moyenne sur la base de test avec gamma ={a:10.4f} est {b:10.2f}\".format(a=gamma, b=\n",
    "                                                                                      np.mean((At@x_star-bt)**2))) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aller plus loin\n",
    "Proposer une implémentation de l'algorithme de gradient stochastique qui utilise plusieurs données (un mini-batch) au lieu d'utiliser qu'une seule donnée. Comparer avec l'algorithme précédent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
